{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **INFO284 Machine Learning Exam, spring 2025**\n",
    "## **Task 1 - Sentiment analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Load data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dataset/Hotel_Reviews.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Read the data into a data frame (pandas) from the csv file\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset/Hotel_Reviews.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1881\u001b[0m     f,\n\u001b[1;32m   1882\u001b[0m     mode,\n\u001b[1;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1889\u001b[0m )\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset/Hotel_Reviews.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the data into a data frame (pandas) from the csv file\n",
    "df = pd.read_csv('dataset/Hotel_Reviews.csv')\n",
    "\n",
    "df.head() # show a overview of the data in the dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the data \n",
    "\n",
    "We get an overview of the data to find out the max and min values of the reviewer scores and to get an idea of the distribution of the scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReviewer_Score\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdescribe()) \u001b[38;5;66;03m# show the statistics of the 'Reviewer_Score' column\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# make a histogram of the 'Reviewer_Score' column\u001b[39;00m\n\u001b[1;32m      3\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReviewer_Score\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mhist(bins\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m) \u001b[38;5;66;03m# 20 bins\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "print(df['Reviewer_Score'].describe()) # show the statistics of the 'Reviewer_Score' column\n",
    "# make a histogram of the 'Reviewer_Score' column\n",
    "df['Reviewer_Score'].hist(bins=20) # 20 bins\n",
    "\n",
    "# print the number of 10.0 scores \n",
    "print(df[df['Reviewer_Score'] == 10.0].shape[0])\n",
    "\n",
    "print(df[df['Reviewer_Score'] == 6.0].shape[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relevant columns are negative and positive reviews. We need to combine them to make it easier to work with the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the review text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Reviewer_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am so angry that i made this post available...</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No real complaints the hotel was great great...</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rooms are nice but for elderly a bit difficul...</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My room was dirty and I was afraid to walk ba...</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You When I booked with your company on line y...</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Reviewer_Score\n",
       "0   I am so angry that i made this post available...             2.9\n",
       "1    No real complaints the hotel was great great...             7.5\n",
       "2   Rooms are nice but for elderly a bit difficul...             7.1\n",
       "3   My room was dirty and I was afraid to walk ba...             3.8\n",
       "4   You When I booked with your company on line y...             6.7"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove 'No Negative' and 'No Positive' from the reviews\n",
    "df['Negative_Review'] = df['Negative_Review'].apply(lambda x: x.replace('No Negative', ''))\n",
    "df['Positive_Review'] = df['Positive_Review'].apply(lambda x: x.replace('No Positive', ''))\n",
    "\n",
    "# merge the two review columns into one\n",
    "df['Review'] = df['Negative_Review'] + ' ' + df['Positive_Review']\n",
    "\n",
    "df = df[[ 'Review','Reviewer_Score']] # select only the columns we need\n",
    "\n",
    "# remove rows with missing values\n",
    "df = df.dropna()\n",
    "\n",
    "df.head() # show a overview of the data in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming review scores to binary values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the reviewer score to be binary\n",
    "df['Sentiment'] = df['Reviewer_Score'].apply(lambda x: 1 if x >= 7.0 else 0)\n",
    "# Downsample the majority class (high review scores)\n",
    "df_majority = df[df['Sentiment'] == 1]\n",
    "df_minority = df[df['Sentiment'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adjusting for sentiment imbalance\n",
    "There is a heavy overweight of positive ('high' scores) in the dataset, so we need to downsample the positive reviews to get a more balanced dataset for our machine learning model to train and test on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Reviewer_Score</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The furnitures were very old the facilities w...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A beautiful hotel Wonderful bathroom and toi...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nothing to dislike  Brilliant service and bri...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shower Bath water was cold called reception s...</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nothing in particular  Perfect location right...</td>\n",
       "      <td>9.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Reviewer_Score  \\\n",
       "0   The furnitures were very old the facilities w...             5.0   \n",
       "1    A beautiful hotel Wonderful bathroom and toi...            10.0   \n",
       "2   Nothing to dislike  Brilliant service and bri...            10.0   \n",
       "3   Shower Bath water was cold called reception s...             5.8   \n",
       "4   Nothing in particular  Perfect location right...             9.2   \n",
       "\n",
       "   Sentiment  \n",
       "0          0  \n",
       "1          1  \n",
       "2          1  \n",
       "3          0  \n",
       "4          1  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downsample majority class\n",
    "df_majority_downsampled = df_majority.sample(len(df_minority))\n",
    "\n",
    "# Combine minority class with downsampled majority class\n",
    "df_balanced = pd.concat([df_majority_downsampled, df_minority])\n",
    "\n",
    "# Shuffle the dataset\n",
    "df_balanced = df_balanced.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "df = df_balanced\n",
    "df.head() # show a overview of the data in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the review text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Reviewer_Score</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the furnitures were very old the facilities w...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a beautiful hotel wonderful bathroom and toi...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nothing to dislike  brilliant service and bri...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>shower bath water was cold called reception s...</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nothing in particular  perfect location right...</td>\n",
       "      <td>9.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Reviewer_Score  \\\n",
       "0   the furnitures were very old the facilities w...             5.0   \n",
       "1    a beautiful hotel wonderful bathroom and toi...            10.0   \n",
       "2   nothing to dislike  brilliant service and bri...            10.0   \n",
       "3   shower bath water was cold called reception s...             5.8   \n",
       "4   nothing in particular  perfect location right...             9.2   \n",
       "\n",
       "   Sentiment  \n",
       "0          0  \n",
       "1          1  \n",
       "2          1  \n",
       "3          0  \n",
       "4          1  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'@[A-Za-z0-9_]+', '', text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "df['Review'] = df['Review'].apply(preprocess_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/runarrossevold/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Reviewer_Score</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>furnitures old facilities poor specially bathr...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>beautiful hotel wonderful bathroom toiletries ...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nothing dislike brilliant service brilliant stadd</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>shower bath water cold called reception severa...</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nothing particular perfect location right next...</td>\n",
       "      <td>9.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Reviewer_Score  \\\n",
       "0  furnitures old facilities poor specially bathr...             5.0   \n",
       "1  beautiful hotel wonderful bathroom toiletries ...            10.0   \n",
       "2  nothing dislike brilliant service brilliant stadd            10.0   \n",
       "3  shower bath water cold called reception severa...             5.8   \n",
       "4  nothing particular perfect location right next...             9.2   \n",
       "\n",
       "   Sentiment  \n",
       "0          0  \n",
       "1          1  \n",
       "2          1  \n",
       "3          0  \n",
       "4          1  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    " \n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "pattern = r'\\b(' + '|'.join(re.escape(word) for word in stop_words) + r')\\b'\n",
    "\n",
    "def remove_stopwords_regex(text):\n",
    "    if isinstance(text, str):  # Ensure it's a string\n",
    "        return re.sub(pattern, '', text)  # Remove stop words\n",
    "    return text\n",
    "\n",
    "df[\"Review\"] = df[\"Review\"].apply(remove_stopwords_regex)\n",
    "df[\"Review\"] = df[\"Review\"].str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/runarrossevold/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Reviewer_Score</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>furnitures old facilities poor specially bathr...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[furnitures, old, facilities, poor, specially,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>beautiful hotel wonderful bathroom toiletries ...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[beautiful, hotel, wonderful, bathroom, toilet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nothing dislike brilliant service brilliant stadd</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[nothing, dislike, brilliant, service, brillia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>shower bath water cold called reception severa...</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0</td>\n",
       "      <td>[shower, bath, water, cold, called, reception,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nothing particular perfect location right next...</td>\n",
       "      <td>9.2</td>\n",
       "      <td>1</td>\n",
       "      <td>[nothing, particular, perfect, location, right...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Reviewer_Score  \\\n",
       "0  furnitures old facilities poor specially bathr...             5.0   \n",
       "1  beautiful hotel wonderful bathroom toiletries ...            10.0   \n",
       "2  nothing dislike brilliant service brilliant stadd            10.0   \n",
       "3  shower bath water cold called reception severa...             5.8   \n",
       "4  nothing particular perfect location right next...             9.2   \n",
       "\n",
       "   Sentiment                                             tokens  \n",
       "0          0  [furnitures, old, facilities, poor, specially,...  \n",
       "1          1  [beautiful, hotel, wonderful, bathroom, toilet...  \n",
       "2          1  [nothing, dislike, brilliant, service, brillia...  \n",
       "3          0  [shower, bath, water, cold, called, reception,...  \n",
       "4          1  [nothing, particular, perfect, location, right...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "def tokenize(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "df['tokens'] = df['Review'].apply(tokenize)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Reviewer_Score</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>tokens</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>furnitures old facilities poor specially bathr...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[furnitures, old, facilities, poor, specially,...</td>\n",
       "      <td>[furnitur, old, facil, poor, special, bathroom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>beautiful hotel wonderful bathroom toiletries ...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[beautiful, hotel, wonderful, bathroom, toilet...</td>\n",
       "      <td>[beauti, hotel, wonder, bathroom, toiletri, co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nothing dislike brilliant service brilliant stadd</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[nothing, dislike, brilliant, service, brillia...</td>\n",
       "      <td>[noth, dislik, brilliant, servic, brilliant, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>shower bath water cold called reception severa...</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0</td>\n",
       "      <td>[shower, bath, water, cold, called, reception,...</td>\n",
       "      <td>[shower, bath, water, cold, call, recept, seve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nothing particular perfect location right next...</td>\n",
       "      <td>9.2</td>\n",
       "      <td>1</td>\n",
       "      <td>[nothing, particular, perfect, location, right...</td>\n",
       "      <td>[noth, particular, perfect, locat, right, next...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Reviewer_Score  \\\n",
       "0  furnitures old facilities poor specially bathr...             5.0   \n",
       "1  beautiful hotel wonderful bathroom toiletries ...            10.0   \n",
       "2  nothing dislike brilliant service brilliant stadd            10.0   \n",
       "3  shower bath water cold called reception severa...             5.8   \n",
       "4  nothing particular perfect location right next...             9.2   \n",
       "\n",
       "   Sentiment                                             tokens  \\\n",
       "0          0  [furnitures, old, facilities, poor, specially,...   \n",
       "1          1  [beautiful, hotel, wonderful, bathroom, toilet...   \n",
       "2          1  [nothing, dislike, brilliant, service, brillia...   \n",
       "3          0  [shower, bath, water, cold, called, reception,...   \n",
       "4          1  [nothing, particular, perfect, location, right...   \n",
       "\n",
       "                                             stemmed  \n",
       "0  [furnitur, old, facil, poor, special, bathroom...  \n",
       "1  [beauti, hotel, wonder, bathroom, toiletri, co...  \n",
       "2  [noth, dislik, brilliant, servic, brilliant, s...  \n",
       "3  [shower, bath, water, cold, call, recept, seve...  \n",
       "4  [noth, particular, perfect, locat, right, next...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Initialize the Porter Stemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stem(tokens):\n",
    "    return [stemmer.stem(token) for token in tokens]\n",
    "\n",
    "df['stemmed'] = df['tokens'].apply(stem)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/runarrossevold/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/runarrossevold/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Reviewer_Score</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>tokens</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>furnitures old facilities poor specially bathr...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[furnitures, old, facilities, poor, specially,...</td>\n",
       "      <td>[furnitur, old, facil, poor, special, bathroom...</td>\n",
       "      <td>[furniture, old, facility, poor, specially, ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>beautiful hotel wonderful bathroom toiletries ...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[beautiful, hotel, wonderful, bathroom, toilet...</td>\n",
       "      <td>[beauti, hotel, wonder, bathroom, toiletri, co...</td>\n",
       "      <td>[beautiful, hotel, wonderful, bathroom, toilet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nothing dislike brilliant service brilliant stadd</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[nothing, dislike, brilliant, service, brillia...</td>\n",
       "      <td>[noth, dislik, brilliant, servic, brilliant, s...</td>\n",
       "      <td>[nothing, dislike, brilliant, service, brillia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>shower bath water cold called reception severa...</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0</td>\n",
       "      <td>[shower, bath, water, cold, called, reception,...</td>\n",
       "      <td>[shower, bath, water, cold, call, recept, seve...</td>\n",
       "      <td>[shower, bath, water, cold, called, reception,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nothing particular perfect location right next...</td>\n",
       "      <td>9.2</td>\n",
       "      <td>1</td>\n",
       "      <td>[nothing, particular, perfect, location, right...</td>\n",
       "      <td>[noth, particular, perfect, locat, right, next...</td>\n",
       "      <td>[nothing, particular, perfect, location, right...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Reviewer_Score  \\\n",
       "0  furnitures old facilities poor specially bathr...             5.0   \n",
       "1  beautiful hotel wonderful bathroom toiletries ...            10.0   \n",
       "2  nothing dislike brilliant service brilliant stadd            10.0   \n",
       "3  shower bath water cold called reception severa...             5.8   \n",
       "4  nothing particular perfect location right next...             9.2   \n",
       "\n",
       "   Sentiment                                             tokens  \\\n",
       "0          0  [furnitures, old, facilities, poor, specially,...   \n",
       "1          1  [beautiful, hotel, wonderful, bathroom, toilet...   \n",
       "2          1  [nothing, dislike, brilliant, service, brillia...   \n",
       "3          0  [shower, bath, water, cold, called, reception,...   \n",
       "4          1  [nothing, particular, perfect, location, right...   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0  [furnitur, old, facil, poor, special, bathroom...   \n",
       "1  [beauti, hotel, wonder, bathroom, toiletri, co...   \n",
       "2  [noth, dislik, brilliant, servic, brilliant, s...   \n",
       "3  [shower, bath, water, cold, call, recept, seve...   \n",
       "4  [noth, particular, perfect, locat, right, next...   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  [furniture, old, facility, poor, specially, ba...  \n",
       "1  [beautiful, hotel, wonderful, bathroom, toilet...  \n",
       "2  [nothing, dislike, brilliant, service, brillia...  \n",
       "3  [shower, bath, water, cold, called, reception,...  \n",
       "4  [nothing, particular, perfect, location, right...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')  # Download additional data for WordNet\n",
    "\n",
    "# Initialize the WordNet Lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize(tokens):\n",
    "    return [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "df['lemmatized'] = df['tokens'].apply(lemmatize)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running MultionmialNB with TF-IDF vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7928\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.81      0.80     17371\n",
      "           1       0.80      0.78      0.79     17370\n",
      "\n",
      "    accuracy                           0.79     34741\n",
      "   macro avg       0.79      0.79      0.79     34741\n",
      "weighted avg       0.79      0.79      0.79     34741\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize the TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the vectorizer on the text\n",
    "X = vectorizer.fit_transform(df['Review'])\n",
    "\n",
    "y = df['Sentiment']\n",
    "\n",
    "# Split the data into training and test sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Initialize Multinomial Naive Bayes classifier\n",
    "mnb_tfidf = MultinomialNB()\n",
    "\n",
    "# Train the model on the training data\n",
    "mnb_tfidf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = mnb_tfidf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running kNN \n",
    "\n",
    "Using k = 1000, as the default k=5 is too low for this dataset, and k=1000 gives better accuracy (0.75) than k=5 (0.58)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7540\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.64      0.72     17371\n",
      "           1       0.71      0.87      0.78     17370\n",
      "\n",
      "    accuracy                           0.75     34741\n",
      "   macro avg       0.77      0.75      0.75     34741\n",
      "weighted avg       0.77      0.75      0.75     34741\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=1000)\n",
    "\n",
    "# Train the kNN model on the training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "\n",
    "# Evaluate the kNN model\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "print(f\"Accuracy: {accuracy_knn:.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_knn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding best k\n",
    "\n",
    "Trying to hyperparameter tune the k value for the kNN model. \n",
    "Having issues as the base algorithm with only one iteration takes 5 minutes to run. \n",
    "Low prospects for hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Perform Grid Search with cross-validation\u001b[39;00m\n\u001b[1;32m     12\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(knn, param_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m grid_search\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Print the best k and corresponding accuracy\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest k: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgrid_search\u001b[38;5;241m.\u001b[39mbest_params_[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_neighbors\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1018\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1013\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1014\u001b[0m     )\n\u001b[1;32m   1016\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1018\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1572\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1570\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1571\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1572\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:964\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    957\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    958\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    960\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    961\u001b[0m         )\n\u001b[1;32m    962\u001b[0m     )\n\u001b[0;32m--> 964\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m    965\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    966\u001b[0m         clone(base_estimator),\n\u001b[1;32m    967\u001b[0m         X,\n\u001b[1;32m    968\u001b[0m         y,\n\u001b[1;32m    969\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[1;32m    970\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[1;32m    971\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[1;32m    972\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[1;32m    973\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[1;32m    974\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[1;32m    975\u001b[0m     )\n\u001b[1;32m    976\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[1;32m    977\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params),\n\u001b[1;32m    978\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)),\n\u001b[1;32m    979\u001b[0m     )\n\u001b[1;32m    980\u001b[0m )\n\u001b[1;32m    982\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    983\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    984\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    985\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    986\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    987\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     73\u001b[0m )\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/parallel.py:136\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:910\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    907\u001b[0m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_error\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    909\u001b[0m fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[0;32m--> 910\u001b[0m test_scores \u001b[38;5;241m=\u001b[39m _score(\n\u001b[1;32m    911\u001b[0m     estimator, X_test, y_test, scorer, score_params_test, error_score\n\u001b[1;32m    912\u001b[0m )\n\u001b[1;32m    913\u001b[0m score_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time \u001b[38;5;241m-\u001b[39m fit_time\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_train_score:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:971\u001b[0m, in \u001b[0;36m_score\u001b[0;34m(estimator, X_test, y_test, scorer, score_params, error_score)\u001b[0m\n\u001b[1;32m    969\u001b[0m         scores \u001b[38;5;241m=\u001b[39m scorer(estimator, X_test, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mscore_params)\n\u001b[1;32m    970\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 971\u001b[0m         scores \u001b[38;5;241m=\u001b[39m scorer(estimator, X_test, y_test, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mscore_params)\n\u001b[1;32m    972\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    973\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(scorer, _MultimetricScorer):\n\u001b[1;32m    974\u001b[0m         \u001b[38;5;66;03m# If `_MultimetricScorer` raises exception, the `error_score`\u001b[39;00m\n\u001b[1;32m    975\u001b[0m         \u001b[38;5;66;03m# parameter is equal to \"raise\".\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_scorer.py:279\u001b[0m, in \u001b[0;36m_BaseScorer.__call__\u001b[0;34m(self, estimator, X, y_true, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m     _kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m sample_weight\n\u001b[0;32m--> 279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_score(partial(_cached_call, \u001b[38;5;28;01mNone\u001b[39;00m), estimator, X, y_true, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_scorer.py:371\u001b[0m, in \u001b[0;36m_Scorer._score\u001b[0;34m(self, method_caller, estimator, X, y_true, **kwargs)\u001b[0m\n\u001b[1;32m    369\u001b[0m pos_label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m is_regressor(estimator) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_pos_label()\n\u001b[1;32m    370\u001b[0m response_method \u001b[38;5;241m=\u001b[39m _check_response_method(estimator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_method)\n\u001b[0;32m--> 371\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m method_caller(\n\u001b[1;32m    372\u001b[0m     estimator, response_method\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, X, pos_label\u001b[38;5;241m=\u001b[39mpos_label\n\u001b[1;32m    373\u001b[0m )\n\u001b[1;32m    375\u001b[0m scoring_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sign \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_score_func(y_true, y_pred, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mscoring_kwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_scorer.py:89\u001b[0m, in \u001b[0;36m_cached_call\u001b[0;34m(cache, estimator, response_method, *args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m response_method \u001b[38;5;129;01min\u001b[39;00m cache:\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cache[response_method]\n\u001b[0;32m---> 89\u001b[0m result, _ \u001b[38;5;241m=\u001b[39m _get_response_values(\n\u001b[1;32m     90\u001b[0m     estimator, \u001b[38;5;241m*\u001b[39margs, response_method\u001b[38;5;241m=\u001b[39mresponse_method, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m     91\u001b[0m )\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     94\u001b[0m     cache[response_method] \u001b[38;5;241m=\u001b[39m result\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_response.py:211\u001b[0m, in \u001b[0;36m_get_response_values\u001b[0;34m(estimator, X, response_method, pos_label, return_response_method_used)\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m pos_label \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m target_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    209\u001b[0m         pos_label \u001b[38;5;241m=\u001b[39m classes[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m--> 211\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m prediction_method(X)\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prediction_method\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict_proba\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict_log_proba\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    214\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m _process_predict_proba(\n\u001b[1;32m    215\u001b[0m         y_pred\u001b[38;5;241m=\u001b[39my_pred,\n\u001b[1;32m    216\u001b[0m         target_type\u001b[38;5;241m=\u001b[39mtarget_type,\n\u001b[1;32m    217\u001b[0m         classes\u001b[38;5;241m=\u001b[39mclasses,\n\u001b[1;32m    218\u001b[0m         pos_label\u001b[38;5;241m=\u001b[39mpos_label,\n\u001b[1;32m    219\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/neighbors/_classification.py:259\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbrute\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m ArgKminClassMode\u001b[38;5;241m.\u001b[39mis_usable_for(\n\u001b[1;32m    257\u001b[0m         X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric\n\u001b[1;32m    258\u001b[0m     ):\n\u001b[0;32m--> 259\u001b[0m         probabilities \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_proba(X)\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputs_2d_:\n\u001b[1;32m    261\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mstack(\n\u001b[1;32m    262\u001b[0m                 [\n\u001b[1;32m    263\u001b[0m                     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_[idx][np\u001b[38;5;241m.\u001b[39margmax(probas, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    266\u001b[0m                 axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    267\u001b[0m             )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/neighbors/_classification.py:366\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m probabilities\n\u001b[1;32m    364\u001b[0m     \u001b[38;5;66;03m# In that case, we do not need the distances to perform\u001b[39;00m\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;66;03m# the weighting so we do not compute them.\u001b[39;00m\n\u001b[0;32m--> 366\u001b[0m     neigh_ind \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkneighbors(X, return_distance\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    367\u001b[0m     neigh_dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/neighbors/_base.py:886\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    883\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    884\u001b[0m         kwds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meffective_metric_params_\n\u001b[0;32m--> 886\u001b[0m     chunked_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m    887\u001b[0m         pairwise_distances_chunked(\n\u001b[1;32m    888\u001b[0m             X,\n\u001b[1;32m    889\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_X,\n\u001b[1;32m    890\u001b[0m             reduce_func\u001b[38;5;241m=\u001b[39mreduce_func,\n\u001b[1;32m    891\u001b[0m             metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meffective_metric_,\n\u001b[1;32m    892\u001b[0m             n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[1;32m    893\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds,\n\u001b[1;32m    894\u001b[0m         )\n\u001b[1;32m    895\u001b[0m     )\n\u001b[1;32m    897\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_method \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mball_tree\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkd_tree\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    898\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m issparse(X):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/pairwise.py:2181\u001b[0m, in \u001b[0;36mpairwise_distances_chunked\u001b[0;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[1;32m   2179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reduce_func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2180\u001b[0m     chunk_size \u001b[38;5;241m=\u001b[39m D_chunk\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m-> 2181\u001b[0m     D_chunk \u001b[38;5;241m=\u001b[39m reduce_func(D_chunk, sl\u001b[38;5;241m.\u001b[39mstart)\n\u001b[1;32m   2182\u001b[0m     _check_chunk_size(D_chunk, chunk_size)\n\u001b[1;32m   2183\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m D_chunk\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/neighbors/_base.py:738\u001b[0m, in \u001b[0;36mKNeighborsMixin._kneighbors_reduce_func\u001b[0;34m(self, dist, start, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Reduce a chunk of distances to the nearest neighbors.\u001b[39;00m\n\u001b[1;32m    712\u001b[0m \n\u001b[1;32m    713\u001b[0m \u001b[38;5;124;03mCallback to :func:`sklearn.metrics.pairwise.pairwise_distances_chunked`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;124;03m    The neighbors indices.\u001b[39;00m\n\u001b[1;32m    736\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    737\u001b[0m sample_range \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(dist\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])[:, \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[0;32m--> 738\u001b[0m neigh_ind \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margpartition(dist, n_neighbors \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    739\u001b[0m neigh_ind \u001b[38;5;241m=\u001b[39m neigh_ind[:, :n_neighbors]\n\u001b[1;32m    740\u001b[0m \u001b[38;5;66;03m# argpartition doesn't guarantee sorted order, so we sort again\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/numpy/core/fromnumeric.py:858\u001b[0m, in \u001b[0;36margpartition\u001b[0;34m(a, kth, axis, kind, order)\u001b[0m\n\u001b[1;32m    779\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_argpartition_dispatcher)\n\u001b[1;32m    780\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21margpartition\u001b[39m(a, kth, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mintroselect\u001b[39m\u001b[38;5;124m'\u001b[39m, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    781\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;124;03m    Perform an indirect partition along the given axis using the\u001b[39;00m\n\u001b[1;32m    783\u001b[0m \u001b[38;5;124;03m    algorithm specified by the `kind` keyword. It returns an array of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    856\u001b[0m \n\u001b[1;32m    857\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 858\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapfunc(a, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124margpartition\u001b[39m\u001b[38;5;124m'\u001b[39m, kth, axis\u001b[38;5;241m=\u001b[39maxis, kind\u001b[38;5;241m=\u001b[39mkind, order\u001b[38;5;241m=\u001b[39morder)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/numpy/core/fromnumeric.py:59\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bound(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Define the parameter grid for RandomizedSearchCV\n",
    "param_dist = {\n",
    "    'n_neighbors': randint(1, 50)\n",
    "}\n",
    "\n",
    "# Initialize the RandomizedSearchCV with KNeighborsClassifier\n",
    "random_search = RandomizedSearchCV(KNeighborsClassifier(), param_distributions=param_dist, n_iter=100, cv=5, scoring='accuracy', random_state=42)\n",
    "\n",
    "# Fit the random search model\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = random_search.best_params_\n",
    "best_score = random_search.best_score_\n",
    "\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"Best Score: {best_score:.4f}\")\n",
    "\n",
    "# Make predictions on the test data using the best estimator\n",
    "y_pred_random_search = random_search.best_estimator_.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_random_search = accuracy_score(y_test, y_pred_random_search)\n",
    "print(f\"Accuracy: {accuracy_random_search:.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_random_search))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing the algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a bar plot to compare the accuracy of the algorithms\n",
    "algorithms = ['MultinomialNB', 'kNN']\n",
    "accuracies = [accuracy, accuracy_knn]\n",
    "\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.bar(algorithms, accuracies, color=['blue', 'red'])\n",
    "plt.xlabel('Algorithm')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy Comparison of MultinomialNB and kNN')\n",
    "plt.ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **TODO**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset exploration and preprocessing**\n",
    "* find relevant columns\n",
    "* check the datatypes of the columns - convert if needed\n",
    "* check for missing values - handle missing values\n",
    "* check for duplicate rows\n",
    "* sjekke tekstlikhet (f.eks. nesten like setninger som kan være semantisk like).\n",
    "* check data distribution (class imbalance, length of text, etc.)\n",
    "  \n",
    "**Clean the Text Data: - text preprocessing**\n",
    "* lowercase text\n",
    "* Remove Noise: special characters, numbers, punctuation, URLs, HTML tags, Emojis, extra whitespace, etc.\n",
    "* Tokenization: Split text into words.\n",
    "* Stopword removal\n",
    "* Lemmatization/Stemming: gjøre begge men vise og skrive litt tekst ish: \"stemming vises her men åpenbart er lemmatization bedre...:\"\n",
    "\n",
    "**Convert Text into Numerical Representation**\n",
    "* Vectorization of the text - TFIDF greiene, bag of words osv\n",
    "* prøv ulike måter\n",
    "* Bag of Words (BoW): Convert text into a numerical representation using word frequency.\n",
    "* TF-IDF (Term Frequency-Inverse Document Frequency): Weigh words based on their importance in the dataset.\n",
    "* Word Embeddings: Use pre-trained models like Word2Vec, GloVe, or FastText for contextual meaning.\n",
    "\n",
    "**Splitting Data for Training and Testing**\n",
    "* Try different data splits (70/30) etc.\n",
    "\n",
    "**Model Selection & Training**\n",
    "* Prøv å justere parametre\n",
    "\n",
    "**Evaluating models**\n",
    "* Use multiple metrics, not just accuracy (e.g., F1-score, precision-recall)\n",
    "* Confusion matrix analysis (to see misclassified examples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
